
# 
# GNN_annot IJCNN 2021 implementation
#   Training and prediction sample generator for GNN, traning against the DAVIS benchmark.
#   @author Viktor Varga
#

#
# INFO:
#   class DAVISSessionIterator encapsulates a single DAVIS session iterator.
#       The state of the session can be queried and updated after a prediction.
#   class GraphDatagenDAVIS_Binary holds all pregenerated data for a single video.
#       After the session state is set, it can generate a new training (or prediction) sample.
#   class GraphTrainingDatasetDAVIS is the top level iterator:
#       Generates training samples and expects prediction submissions.
#       Holds multiple session iterators (DAVISSessionIterator) and 
#           a video datagen iterator (GraphDatagenDAVIS_Binary) for each video.
#       Multiple DAVISSessionIterator sessions are maintained and randomly selected in each iteration.
#       The state of the selected session is queried and then the appropriate GraphDatagenDAVIS_Binary instance
#           is set with this state to generate a new training sample.
#       The session iterators store their own state and also store 
#           the state of the GraphDatagenDAVIS_Binary from the previous step (as "3rdparty state").
#       

import time
import numpy as np
import dgl
import torch
from scipy.ndimage.morphology import distance_transform_cdt
from sklearn.linear_model import LogisticRegression

from video_data import VideoData
from segmentation import Segmentation
from datasets import DAVIS17
import config as Config
import util.util as Util
import util.imutil as ImUtil
import util.davis_utils as DavisUtils

from davisinteractive.session import DavisInteractiveSession

class GraphDatagenDAVIS_Binary:
    
    '''
    A SINGLE class instace PER VIDEO.
    TWO MODES (train or predict):
        -> TRAINING SAMPLE: a random binary partitioning of the multiclass label set is generated and the training sample
                                is converted to binary labeling with it
        -> PREDICTION SAMPLE: if N_LABELS == 2: 
                                if PREDICTION_DOUBLE_ONE_VS_REST is False: a single prediction is made as the 
                                    classification problem is already binary
                                if PREDICTION_DOUBLE_ONE_VS_REST is True: same as the other case, but another prediction
                                    is executed with inverted fg-bg labels
                              elif N_LABELS > 2: the generator generates binary prediction samples following the one-vs-rest strategy;
                                if PREDICTION_DOUBLE_ONE_VS_REST is False: n_labels number of samples are generated where
                                    in each round a different category is assigned fg, and all other categories are assigned bg
                                if PREDICTION_DOUBLE_ONE_VS_REST is True: 2*n_labels number of samples are generated
                                    an extra evaluation round is executed where fg and bg are swapped

    STATE is needed to be set before generating a sample with:
        - previous predictions (prob vecs) by model in the current session
        - all seed points in the current session (generated by this iterator)
        - all propagated seed points in the current session (generated by this iterator)
        - idx of the newly annotated frame and the new scribbles (generated by DAVIS session iterator)

    Member fields:
        videodata: VideoData instance
        label_model: None OR LabelModel subclass instance
        n_labels: int; number of categories in the video (independent of whether binary of multiclass mode is used)
        curr_bin_label_split: tuple(bg_labelset: array-like, fg_labelset: array-like)

        mode: str; 'train' or 'predict'
        seedprop_alg: SeedPropagation subclass instance
        iter_idx: int; idx of previous sample generated

        # SESSION STATE
        state_prev_preds: None OR ndarray(n_segs, p_dim) of float
        state_seed_hist: list(n_interactions) of tuple(annot_fr_idx - int, scribble_arr - ndarray(n_seeds, 3:[py, px, lab] of i32)
        state_seed_prop_hist: list(n_interactions) of dict{fr_idx - int: scribble_arr - ndarray(n_seeds, 3:[py, px, lab] of i32}
        new_annot_fr_idx: None OR int
        new_scribbles: None OR dict{lab - int: list(n_scribbles_with_lab) of ndarray(n_points_in_scribble, 2:[y,x]) of int32}
    '''

    def __init__(self, vidname, videodata, mode, label_model, seedprop_alg):
        self.vidname = vidname  # debug info
        self.videodata = videodata
        self.n_labels = videodata.get_data('n_labels')
        assert self.n_labels >= 2
        assert mode in ['train', 'predict']
        self.mode = mode
        self.iter_idx = -1
        self.seedprop_alg = seedprop_alg
        self.label_model = label_model
        self.curr_bin_label_split = None

        # init session state to None
        self.new_annot_fr_idx = None
        self.new_scribbles = None
        self.reset_session_state()
        #

    def __iter__(self):
        return self

    def __next__(self):
        '''
        Returns:
            'train' MODE:
                torch tensors - the assembeld batch, see 'self._assemble_batch()'
            'predict' MODE:
                DGLGraph - the graph including the node/edge features
        '''
        self.iter_idx += 1
        if self.mode == 'train':
            g, node_ys = self._generate_sample()
            batch = self._assemble_batch((g, node_ys), training=True)
            return batch
        else:
            rets = self._generate_sample()
            if rets is None:
                raise StopIteration
            g, _ = rets
            return g

    def get_current_binary_label_split(self):
        '''
        Returns the multiclass labels associated with the fg and the bg binary labels in the previously generated sample.
        Returns:
            tuple(bg_labelset: array-like, fg_labelset: array-like)
        '''
        return self.curr_bin_label_split

    def reset_session_state(self):
        self.state_prev_preds = None
        self.state_seed_hist = []
        self.state_seed_prop_hist = []

    def get_session_state(self):
        '''
        Returns:
            self.state_prev_preds: <type described in class members docstring>
            self.state_seed_hist: <type described in class members docstring>
            self.state_seed_prop_hist: <type described in class members docstring>
        '''
        return self.state_prev_preds, self.state_seed_hist, self.state_seed_prop_hist

    def set_session_state(self, new_annot_fr_idx, new_scribbles, state_prev_preds, state_seed_hist, state_seed_prop_hist):
        '''
        Parameters:
            new_annot_fr_idx: int
            new_scribbles: dict{lab - int: list(n_scribbles_with_lab) of ndarray(n_points_in_scribble, 2:[y,x]) of int32}
            state_prev_preds: <type described in class members docstring>
            state_seed_hist: <type described in class members docstring>
            state_seed_prop_hist: <type described in class members docstring>
        '''
        self.new_annot_fr_idx = new_annot_fr_idx
        self.new_scribbles = new_scribbles
        self.state_prev_preds = state_prev_preds
        self.state_seed_hist = state_seed_hist              # does not contain the new scribbles
        self.state_seed_prop_hist = state_seed_prop_hist    # does not contain the propagated new scribbles

    def reset_prediction_iterator(self):
        '''
        Reset iterator. Only for prediction mode.
        '''
        assert self.mode == 'predict'
        self.iter_idx = -1
        self.new_annot_fr_idx = None
        self.new_scribbles = None
        self.reset_session_state()
    
    # PRIVATE

    def _get_full_session_state(self):
        '''
        Returns all five parts of the session state that was set with self.set_session_state() previously.
        '''
        return self.new_annot_fr_idx, self.new_scribbles, self.state_prev_preds, self.state_seed_hist, self.state_seed_prop_hist
    
    '''
    FEATURE LIST:
    Constant node features ('fs'):
        #0..1: mean occl fw,bw [0..1]
        #2..7: mean_im_lab, std_im_lab [0..1]
        #8: (log2 / 20.) node size
        #9: is image border node (border_sp) {0,1}
    Constant edge features (per direction), ('fs'):
        #0: lab_dist [approx. 0..1] (SAME IN BOTH DIRS)
        #1..6: of_fw_diff, of_bw_diff [[0,pi], any real number, [0,1], [0,pi], any real number, [0,1]] (SAME IN BOTH DIRS)
            [abs_angular_diff, min_mag, rel_mag]
        #7..10: flow_edges_gnn (VARIES BY DIR), all zero if not flow edge
        #11: is spatial edge {0,1} (SAME IN BOTH DIRS)
        #12: is flow edge {0,1} (SAME IN BOTH DIRS)

    Dynamic node features ('fs'):
        #10..11: if any annot / new annot is present in frame (nodes in whole frame are assigned 1.)
        #12..13: bg annot present, fg annot present
        #14..15: bg prop annot present, fg prop annot present
        #16: label model fg/bg prediction probability [0,1] - 1 is fg, 0 is bg
        #17: previous fg/bg prediction probability [0,1] - 1 is fg, 0 is bg
        (OPTIONAL) #18: session idx if Config.GNN_ENABLE_NODE_FEATURE_SESSION_STEP_IDX is enabled
    '''
    def _prepare_constant_nodefs_arr(self):
        '''
        Returns a new nodefs array with constant node features written in it and place for dynamic features is left as zeros.
        Returns:
            nodefs: ndarray(n_nodes, 15) of float32;
        '''
        n_node_features = 19 if Config.GNN_ENABLE_NODE_FEATURE_SESSION_STEP_IDX is True else 18
        nodefs = np.zeros((self.videodata.get_seg().get_n_segs_total(), n_node_features), dtype=np.float32)
        nodefs[:,0] = self.videodata.get_data('mean_occl_fw_seg')[:,0]
        nodefs[:,1] = self.videodata.get_data('mean_occl_bw_seg')[:,0]
        nodefs[:,2:5] = self.videodata.get_data('mean_lab_seg')
        nodefs[:,5:8] = self.videodata.get_data('std_lab_seg')
        nodefs[:,8] = np.log2(self.videodata.get_seg().get_seg_sizes()) / 20.
        nodefs[:,9] = self.videodata.get_data('border_seg')
        return nodefs

    def _prepare_constant_edgefs_arr(self):
        '''
        Returns a new edgefs array with constant edge features written in it and place for dynamic features is left as zeros.
        Returns:
            edges: ndarray(n_edges, 2:[from_ID, to_ID]) of int32; unique edges where ID_from < ID_to
            edgefs: ndarray(n_edges, 2:[from -> to, to -> from], 13) of float32;
        '''
        spatial_edges = self.videodata.get_data('spatial_edges')
        flow_edges = self.videodata.get_data('flow_edges') 
        merger_idxs = self.videodata.get_data('all_edges_merger_idxs')
        merger_idxs_part1_mask = merger_idxs < spatial_edges.shape[0]

        edges = np.concatenate([spatial_edges, flow_edges], axis=0)[merger_idxs,:]
        edgefs = np.zeros((edges.shape[0], 2, 13), dtype=np.float32)
        edgefs[:,:,0] = self.videodata.get_data('mean_lab_diff_edgefs')
        edgefs[:,:,1:4] = self.videodata.get_data('mean_of_fw_diff_edgefs')[:,None,:]
        edgefs[:,:,4:7] = self.videodata.get_data('mean_of_bw_diff_edgefs')[:,None,:]
        edgefs[~merger_idxs_part1_mask,:,7:11] = self.videodata.get_data('flow_edge_fs')   # bidir
        edgefs[merger_idxs_part1_mask,:,11] = 1.
        edgefs[~merger_idxs_part1_mask,:,12] = 1.
        return edges, edgefs

    def _add_new_seeds_to_state(self, n_init_seeds_sampled, n_seeds_sampled):
        '''
        Generates seed points from new scribbles and adds them to state. 
        Propagates the new seed points and adds those to state as well.
        Parameters:
            n_init_seeds_sampled: int; number of seeds sampled from new scribbles in iter#0
            n_seeds_sampled: int; number of seeds sampled from new scribbles in rounds starting from iter#1
        Modifies members:
            state_prev_preds, state_seed_hist, state_seed_prop_hist
        '''
        assert self.new_scribbles is not None
        n_seeds_per_cat = n_init_seeds_sampled if len(self.state_seed_hist) == 0 else n_seeds_sampled
        new_seed_points = DavisUtils.davis_scribbles2seeds_uniform(self.new_scribbles, (480, 854), n_seeds_per_cat, \
                                                                   generate_bg=(len(self.state_seed_hist) == 0))  # (n_seeds, 3:[y, x, lab])
        self.state_seed_hist.append((self.new_annot_fr_idx, new_seed_points))
        new_seed_fr_idxs = np.full(new_seed_points.shape[:1], dtype=np.int32, fill_value=self.new_annot_fr_idx)
        if self.seedprop_alg is not None:
            new_prop_seeds = self.seedprop_alg.propagate(self.vidname, new_seed_fr_idxs, new_seed_points[:,:2], new_seed_points[:,2])
        else:
            new_prop_seeds = {}
        self.state_seed_prop_hist.append(new_prop_seeds)


    def _generate_sample(self):
        '''
        Generates a new training sample or the next prediction sample.
        Returns:
            g: DGLGraph - the graph including the node/edge features & input label distribution vector
            true_labels_bin: ndarray(n_nodes,) of fl32
        '''
        N_SEEDS_PER_CAT_INITIAL = 100
        N_SEEDS_PER_CAT_LATER = 100
        N_MAX_LABMODEL_TRAIN_SAMPLES = 400

        if self.mode == 'predict':
            n_pred_iters_per_round = 1 if self.n_labels == 2 else self.n_labels
            n_max_iters = 2*n_pred_iters_per_round if Config.PREDICTION_DOUBLE_ONE_VS_REST else n_pred_iters_per_round
            if self.iter_idx >= n_max_iters:
                return None

        # NODE FEATURES #0 .. #9, EDGE FEATURES: generate constant node & edge features
        nodefs = self._prepare_constant_nodefs_arr()
        edges, edgefs = self._prepare_constant_edgefs_arr()

        # convert new DAVIS scribbles to seed points and propagate them with seedprop, finally add them to state
        #if ((self.mode == 'train') or (self.iter_idx == 0)) and (self.new_scribbles is not None):
        if self.new_scribbles is not None:
            #print("GraphDatagenDAVIS_Binary._add_new_seeds_to_state(): sampling seeds & adding them to state - mode, iter:", self.mode, self.iter_idx)
            self._add_new_seeds_to_state(N_SEEDS_PER_CAT_INITIAL, N_SEEDS_PER_CAT_LATER)
            self.new_scribbles = None

        # NODE FEATURE #10: 1 for all nodes in annotated frames
        for (annot_fr_idx, _) in self.state_seed_hist:
            annot_fr_seg_id_offset, annot_fr_seg_id_endoffset = self.videodata.get_seg().get_fr_seg_id_offset(annot_fr_idx), \
                                                                self.videodata.get_seg().get_fr_seg_id_end_offset(annot_fr_idx)
            nodefs[annot_fr_seg_id_offset:annot_fr_seg_id_endoffset, 10] = 1.

        # NODE FEATURE #11: 1 for all nodes in the whole newly annotated frame
        new_annot_fr_seg_id_offset, new_annot_fr_seg_id_endoffset = self.videodata.get_seg().get_fr_seg_id_offset(self.new_annot_fr_idx), \
                                                                    self.videodata.get_seg().get_fr_seg_id_end_offset(self.new_annot_fr_idx)
        nodefs[new_annot_fr_seg_id_offset:new_annot_fr_seg_id_endoffset, 11] = 1.

        # generate binary label split: 
        #   if training -> random split
        #   if prediction & n_labels == 2 -> single prediction per round
        #   if prediction & n_labels > 2 -> iterate through OvR using self.iter_idx.
        if self.mode == 'train':
            labelset_fg = np.random.choice(self.n_labels, size=(np.random.randint(1, self.n_labels),), replace=False)
            labelset_bg = np.setdiff1d(np.arange(self.n_labels), labelset_fg)
        elif self.mode == 'predict':
            fg_label = self.iter_idx % n_pred_iters_per_round
            labelset_fg = np.array([fg_label])
            labelset_bg = np.setdiff1d(np.arange(self.n_labels), labelset_fg)
            if self.iter_idx >= n_pred_iters_per_round:
                assert Contig.PREDICTION_DOUBLE_ONE_VS_REST is True
                labelset_bg, labelset_fg = labelset_fg, labelset_bg   # swap fg and bg labels if Config.PREDICTION_DOUBLE_ONE_VS_REST is True
        self.curr_bin_label_split = (labelset_bg, labelset_fg)
        multi_to_bin_lab = np.arange(self.n_labels, dtype=np.int32)
        multi_to_bin_lab[labelset_bg] = 0
        multi_to_bin_lab[labelset_fg] = 1

        # get true labels
        true_labels_orig = self.videodata.get_data('annot_seg').astype(np.int32)
        assert true_labels_orig.ndim == 1
        true_labels_bin = multi_to_bin_lab[true_labels_orig].astype(np.float32)   # (n_nodes,) of fl32 {0., 1.}

        # NODE FEATURE #12, 13: bg & fg annot
        all_annotated_nodes_bin = []
        for (annot_fr_idx, seed_points) in self.state_seed_hist:
            fr_idxs = np.full(seed_points.shape[:1], dtype=np.int32, fill_value=annot_fr_idx)
            seg_ids = self.videodata.get_seg().get_seg_ids_from_coords(fr_idxs, seed_points[:,:2], framewise_seg_ids=False)
            bin_labs = multi_to_bin_lab[seed_points[:,2]]
            all_annotated_nodes_bin.append(np.stack([seg_ids, bin_labs], axis=1))
            bg_segs = bin_labs == 0
            nodefs[seg_ids[bg_segs], 12] = 1.
            nodefs[seg_ids[~bg_segs], 13] = 1.

        # NODE FEATURE #14, 15: bg & fg prop annot
        all_prop_nodes_bin = []
        for prop_dict in self.state_seed_prop_hist:
            for fr_idx, prop_points in prop_dict.items():
                fr_idxs = np.full(prop_points.shape[:1], dtype=np.int32, fill_value=fr_idx)
                seg_ids = self.videodata.get_seg().get_seg_ids_from_coords(fr_idxs, prop_points[:,:2], framewise_seg_ids=False)
                bin_labs = multi_to_bin_lab[prop_points[:,2]]
                all_prop_nodes_bin.append(np.stack([seg_ids, bin_labs], axis=1))
                bg_segs = bin_labs == 0
                nodefs[seg_ids[bg_segs], 14] = 1.
                nodefs[seg_ids[~bg_segs], 15] = 1.

        # NODE FEATURE #16: label model fg/bg prediction probability, in [0,1], where 1 represents fg and 0 is bg
        annot_nodes_bin = np.concatenate(all_annotated_nodes_bin, axis=0)  # (n_nodes, 2:[seg_id, bin_label])
        prop_nodes_bin = np.concatenate(all_prop_nodes_bin, axis=0) if len(all_prop_nodes_bin) > 0 \
                                        else np.zeros((0,2), dtype=annot_nodes_bin.dtype) # (n_nodes, 2:[seg_id, label])   # only used in debug
        n_max_labmodel_train_samples = min(N_MAX_LABMODEL_TRAIN_SAMPLES, annot_nodes_bin.shape[0])
        n_samples_per_cat = max(int(n_max_labmodel_train_samples/self.n_labels), 10)
        u_annot_nodes_bin, c_annot_nodes_bin = np.unique(annot_nodes_bin[:,1], return_counts=True)
        #print("DATAGEN_DAVISb DEBUG INFO --->")
        #print("    vidname:", self.vidname, "n_labels:", self.n_labels)
        #print("    multi -> bin lab assign:", multi_to_bin_lab)
        #print("    annot_nodes_bin u, c:", u_annot_nodes_bin, c_annot_nodes_bin)
        n_labels_present = u_annot_nodes_bin.shape[0]

        if n_labels_present != 2:
            #print("Note: Not all labels were present in the anotation available.")
            assert n_labels_present == 1
            lab_present = u_annot_nodes_bin[0]
            nodefs[:, 16] = float(lab_present)
        else:
            labmodel_train_annot_idxs = Util.random_sample_balanced(annot_nodes_bin[:,1], n_samples_per_cat, n_cats=n_labels_present)
            labmodel_train_ids = annot_nodes_bin[labmodel_train_annot_idxs, 0]
            labmodel_train_ys = np.broadcast_to(np.arange(n_labels_present)[:,None], labmodel_train_ids.shape).reshape(-1).copy()
            #print("    labmodel tr y u, c:", np.unique(labmodel_train_ys, return_counts=True))
            labmodel_train_ids = labmodel_train_ids.reshape(-1)

            #   fit label model to annotated nodes
            if isinstance(self.label_model, LogisticRegression):
                assert self.label_model.solver == 'lbfgs', "'lbfgs' solver in 'auto' multi_class mode will use CE loss, which is faster than OVR method"
            self.label_model.reset(n_labels_present)
            labmodel_train_xs = self.videodata.get_data('fmap_seg')[labmodel_train_ids,:]   # (n_train_sps, n_features)
            assert labmodel_train_xs.shape[0] == labmodel_train_ys.shape[0]
            self.label_model.fit(labmodel_train_xs, labmodel_train_ys)  # up to 1 sec

            #   predict all nodes with label model
            xs_to_pred = self.videodata.get_data('fmap_seg')   # (n_sps, n_features)
            ys_pred = self.label_model.predict(xs_to_pred, return_probs=True)   # (n_nodes, n_labels)
            assert ys_pred.shape == (xs_to_pred.shape[0], n_labels_present)
            assert np.amin(ys_pred) >= 0.
            assert np.amax(ys_pred) <= 1.
            nodefs[:, 16] = ys_pred[:,1]

        # NODE FEATURE #17: prev fg/bg prediction probability [0,1] - 1 is fg, 0 is bg
        if self.state_prev_preds is None:
            nodefs[:, 17] = 0.5
        else:
            assert self.state_prev_preds.ndim == 2  # assert prob vecs
            fg_prob_preds = np.sum(self.state_prev_preds[:,labelset_fg], axis=-1)
            nodefs[:, 17] = fg_prob_preds

        # (OPTIONAL) NODE FEATURE #18: davis session idx as node feature
        if Config.GNN_ENABLE_NODE_FEATURE_SESSION_STEP_IDX is True:
            nodefs[:, 18] = float(len(self.state_seed_hist)-1)/8.

        # convert bidir edges to unidir: similar to concatenating efs[:,0,:] and efs[:,1,:]
        unidir_edges_from = edges.T.reshape(-1)
        unidir_edges_to = edges[:,::-1].T.reshape(-1)
        edgefs_directed = np.concatenate([edgefs[:,0,:], edgefs[:,1,:]], axis=0)

        # create DGL graph from self.edges and self.nodefs, self.edgefs copies
        g = dgl.DGLGraph((unidir_edges_from, unidir_edges_to))   # similar to concatenating e[:,0] and e[:,1]
        g.ndata['fs'] = nodefs
        g.edata['fs'] = edgefs_directed
        print("GEN davis b - vidname: ", self.vidname, " - n_nodes annotated: ", annot_nodes_bin.shape[0],\
                 " - n_nodes with prop seed: ", prop_nodes_bin.shape[0],\
                 " - node/edge_count: ", nodefs.shape[0], edges.shape[0]*2)
        return g, true_labels_bin

    def _assemble_batch(self, batch, training):
        '''
        Assembles batches from samples generated by training data generators.
            size 1 batches are supported only in this implementation
        Parameters:
            batch: tuple(DGLGraph, ndarray(n_nodes) of int32) IF 'training' == True
                                                  OR DGLGraph IF 'training' == False
            training: bool
        '''
        if training:   # TODO only used in training mode, training param necessary?
            g, node_ys = batch
            assert node_ys.ndim == 1
            batch_ys = torch.tensor(np.concatenate([node_ys[:,None]], axis=0))   # Tensor(n_nodes, 1) of fl32, TODO use reshape (needed?) instead
        else:
            g = batch
        assert isinstance(g, dgl.DGLGraph)
        n_nodes, n_edges = g.number_of_nodes(), g.number_of_edges()
        batch_snorm_n = [torch.FloatTensor(n_nodes,1).fill_(1./float(n_nodes))]
        batch_snorm_e = [torch.FloatTensor(n_edges,1).fill_(1./float(n_edges))]
        batch_snorm_n = torch.cat(batch_snorm_n, dim=0).sqrt()
        batch_snorm_e = torch.cat(batch_snorm_e, dim=0).sqrt()
        batch_gs = dgl.batch([g])
        if training:
            return batch_gs, batch_ys, batch_snorm_n, batch_snorm_e
        else:
            return batch_gs, batch_snorm_n, batch_snorm_e
        
    # END OF GraphDatagenDAVIS_Binary class


class DAVISSessionIterator:
    '''

    !!! Note: requires the modified version of the davisinteractive package.
    Iterator encapsulating a DAVIS benchmark session.
    The iterator can be used to store any external state information corresponding to the session,
        see 'self.store_3rdparty_state(..)', 'self.get_3rdparty_state()' methods.

    Member fields:
        session: DavisInteractiveSession
        scrib_iter: DAVIS scribbles iterator

        curr_vidname: str
        prev_scrib_dict, curr_scrib_dict: dict; the dict format is the same returned by the DAVIS scribbles iterator
        scrib_hist: list(n_scribble_interactions) of tuple(annot_fr_idx - int, scribble_arrs - dict{
                                lab - int: list(n_scribbles_with_lab) of ndarray(n_points_in_scribble, 2:[y,x]) of int32}

        state_obj: <any type of object>; member to store any 3rd party state information about the session state
        step_idx: int
    '''

    def __init__(self, subset, n_interactions):
        assert subset in ['train0', 'train1']    # this class should be only used for training
        self.session = DavisInteractiveSession(host='localhost',
                            user_key=None,
                            davis_root=DAVIS17.DAVIS_ROOT_FOLDER,
                            subset=subset,
                            shuffle=True,
                            max_time=2**30,     # time limit disabled
                            max_nb_interactions=n_interactions,
                            metric_to_optimize='J',
                            report_save_dir=None)       # saving report is disabled
        self.session.__enter__()
        self.scrib_iter = self.session.scribbles_iterator()
        self.curr_vidname = None
        self.prev_scrib_dict = None
        self.curr_scrib_dict = None
        self.scrib_hist = []
        self.state_obj = None
        self.step_idx = -1

    def __iter__(self):
        return self

    def __next__(self):
        '''
        Returns:
            self.curr_vidname: str
            is_new_sequence: bool
            new_annot_fr_idx: int
            new_scribbles_dict: dict{lab - int: list(n_scribbles_with_lab) of ndarray(n_points_in_scribble, 2:[y,x]) of int32}
        '''
        self.curr_vidname, scribbles_dict, is_new_sequence = next(self.scrib_iter)   # raises StopIteration exception if expired
        if is_new_sequence:
            self.prev_scribble_dict = None
            self.curr_scribble_dict = None
            self.scrib_hist = []
            self.step_idx = -1
            print("DAVISSessionIterator DEBUG INFO - new seq started:", self.curr_vidname)
        self.step_idx += 1
        self.prev_scribble_dict = self.curr_scribble_dict
        self.curr_scribble_dict = scribbles_dict
        new_annot_fr_idx, new_scribbles_dict = DavisUtils.get_new_scribbles(self.curr_vidname, self.prev_scribble_dict, self.curr_scribble_dict, (480, 854))
        self.scrib_hist.append((new_annot_fr_idx, new_scribbles_dict))

        return self.curr_vidname, is_new_sequence, new_annot_fr_idx, new_scribbles_dict

    def clear_3rdparty_state(self):
        self.state_obj = None

    def get_3rdparty_state(self):
        '''
        Returns the state of the model.
        Returns:
            state_obj: <any type of object>
        '''
        return self.state_obj

    def store_3rdparty_state(self, state_obj):
        '''
        Stores the state of the model.
        Parameters:
            state_obj: <any type of object>
        '''
        self.state_obj = state_obj

    def submit_predictions(self, pred_label_im):
        '''
        Parameters:
            pred_label_im: ndarray(n_frames, sy, sx) of int32; the prediction in image form - to submit to DAVIS session
        '''
        assert pred_label_im.ndim == 3
        assert (Config.TRAINING_DAVIS_SESSION_FRAME_QUERY_POLICY is None) or \
               (Config.TRAINING_DAVIS_SESSION_FRAME_QUERY_POLICY in ['random_uniform', 'random_linear_distance_prob'])
        # resize before submitting if custom video size
        if self.curr_vidname in DAVIS17.CUSTOM_IMSIZE_DICT.keys():
            pred_label_im = ImUtil.fast_resize_video_nearest_singlech(pred_label_im, DAVIS17.CUSTOM_IMSIZE_DICT[self.curr_vidname])

        # select frame to query from benchmark
        frames_already_queried = [fr_idx for (fr_idx, _) in self.scrib_hist]
        if Config.TRAINING_DAVIS_SESSION_FRAME_QUERY_POLICY is None:
            frames_to_query = None
        elif Config.TRAINING_DAVIS_SESSION_FRAME_QUERY_POLICY == 'random_uniform':
            frames_not_queried_yet = np.setdiff1d(np.arange(pred_label_im.shape[0]), frames_already_queried)
            frames_to_query = [np.random.choice(frames_not_queried_yet)]
        elif Config.TRAINING_DAVIS_SESSION_FRAME_QUERY_POLICY == 'random_linear_distance_prob':
            frame_dists = np.ones(pred_label_im.shape[:1], dtype=np.int32)
            frame_dists[frames_already_queried] = 0
            frame_dists = distance_transform_cdt(frame_dists)
            frame_dists = frame_dists / float(np.sum(frame_dists))
            frames_to_query = [np.random.choice(pred_label_im.shape[0], p=frame_dists)]
        print("DAVISSessionIterator DEBUG INFO - frames to query:", frames_to_query)

        # submit image format predictions and next frame to query to DAVIS benchmark
        DavisUtils.fix_label_image_error(self.curr_vidname, pred_label_im)
        self.session.submit_masks(pred_label_im, next_scribble_frame_candidates=frames_to_query)

    def destroy(self):
        self.session.__exit__(None, None, None)

    # END OF DAVISSessionIterator class


class GraphTrainingDatasetDAVIS:

    '''
    Training/validation dataset generation. Multiprocessing is not supported.
    A single instance should be initialized for training and another one for validation.

    Member fields:
        videodata_dict: dict{vidname - str: SegLabeling}
        lab_model_init_fn: Callable, signature is (,) -> LabelModel

        session_gens: list(n_parallel_sessions) of DAVISSessionIterator instances
        videogens: dict{vidname - str: GraphDatagenDAVIS_Binary}
        lab_model: LabelModel instance

        n_parallel_sessions: int; maximum number of DAVIS sessions open at once
        davis_subset: str; the dataset subset upon which the davis session will iterate

        curr_vidgen: GraphDatagenDAVIS_Binary instance, the video data generator that produced the previous sample
        curr_sess_idx: int
        curr_vidname: str
        submit_up_to_date: bool; to ensure that __next__() and submit_predictions() are called alternately
    '''

    def __init__(self, videodata_dict, lab_model_init_fn, n_parallel_sessions, davis_subset, seedprop_alg):
        self.videodata_dict = videodata_dict
        self.lab_model_init_fn = lab_model_init_fn
        assert 1 <= n_parallel_sessions <= 10
        self.n_parallel_sessions = n_parallel_sessions
        self.davis_subset = davis_subset
        self.submit_up_to_date = True
        self.seedprop_alg = seedprop_alg

        # init label models: one instance for each worker
        self.lab_model = lab_model_init_fn()

        # init session generators: one for each parallel session
        self.session_gens = [DAVISSessionIterator(subset=self.davis_subset, n_interactions=Config.TRAINING_DAVIS_N_INTERACTIONS)\
                                                                                         for _ in range(n_parallel_sessions)]

        # init video graph data generators: one for each video
        self.videogens = {vidname: GraphDatagenDAVIS_Binary(vidname, videodata, 'train', \
                           self.lab_model, seedprop_alg) for vidname, videodata in list(self.videodata_dict.items())}
        self.curr_vidgen = None

    def get_curr_vidgen(self):
        return self.curr_vidgen

    def __iter__(self):
        return self

    def __next__(self):
        '''
        Returns:
            batch: <same as returned by the currently used GraphDatagenDAVIS_Binary instance>
        '''
        assert self.submit_up_to_date == True

        # random select a session
        self.curr_sess_idx = np.random.randint(len(self.session_gens))
        chosen_session = self.session_gens[self.curr_sess_idx]

        # sample session iterator
        try:
            self.curr_vidname, is_new_sequence, new_annot_fr_idx, new_scribbles = next(chosen_session)
        except StopIteration:
            # if session is exhausted, replace with a new one
            self.session_gens[self.curr_sess_idx].destroy()
            print("GraphTrainingDatasetDAVIS: new DAVISSessionIterator started, ID#" + str(self.curr_sess_idx) + " in " + self.davis_subset)
            self.session_gens[self.curr_sess_idx] = DAVISSessionIterator(subset=self.davis_subset, \
                                                                         n_interactions=Config.TRAINING_DAVIS_N_INTERACTIONS)
            chosen_session = self.session_gens[self.curr_sess_idx]
            self.curr_vidname, is_new_sequence, new_annot_fr_idx, new_scribbles = next(chosen_session)
        print("GraphTrainingDatasetDAVIS: sampling from DAVISSessionIterator ID#" + str(self.curr_sess_idx) + \
                " in " + self.davis_subset + ", step#" + str(chosen_session.step_idx) + ", fr#" + str(new_annot_fr_idx))

        # get previously stored datagen state from the session iterator, set datagen with this state
        self.curr_vidgen = self.videogens[self.curr_vidname]
        datagen_state_dict = chosen_session.get_3rdparty_state()
        if is_new_sequence:
            self.curr_vidgen.reset_session_state()
            chosen_session.clear_3rdparty_state()
            _, state_seed_hist, state_seed_prop_hist = self.curr_vidgen.get_session_state()
            datagen_state_dict = {'prev_pred': None, 'seed_hist': state_seed_hist, 'seed_prop_hist': state_seed_prop_hist}

        self.curr_vidgen.set_session_state(new_annot_fr_idx, new_scribbles, datagen_state_dict['prev_pred'], \
                                                datagen_state_dict['seed_hist'], datagen_state_dict['seed_prop_hist'])

        # generate training sample with the GraphDatagenDAVIS_Binary instance for the corresponding video
        #   training sample is already packed into a batch
        batch = next(self.curr_vidgen)
        self.submit_up_to_date = False
        return batch


    def submit_predictions(self, pred_probs):
        '''
        Parameters:
            pred_probs: ndarray(n_nodes, p_dim) of float
        '''
        assert pred_probs.ndim == 2

        # convert predictions to mask
        assert self.curr_vidgen is self.videogens[self.curr_vidname]
        curr_seg_arr = self.videodata_dict[self.curr_vidname].get_seg().get_seg_im(framewise_seg_ids=False)
        pred_labels = np.argmax(pred_probs, axis=-1)
        pred_label_im = pred_labels[curr_seg_arr]

        # get session state from video data generator and store it in the session iterator
        _, state_seed_hist, state_seed_prop_hist = self.curr_vidgen.get_session_state()
        chosen_session = self.session_gens[self.curr_sess_idx]
        chosen_session.store_3rdparty_state({'prev_pred': pred_probs, 'seed_hist': state_seed_hist,\
                                                                  'seed_prop_hist': state_seed_prop_hist})
        # submit predictions to DAVIS benchmark
        assert self.submit_up_to_date == False
        self.session_gens[self.curr_sess_idx].submit_predictions(pred_label_im)
        self.submit_up_to_date = True

    # END OF GraphTrainingDatasetDAVIS class

