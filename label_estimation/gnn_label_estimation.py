
# 
# GNN_annot IJCNN 2021 implementation
#   Training and prediction code for GNNs.
#   @author Viktor Varga, 
#       based on
#           Dwivedi et al. 2020, "Benchmarking Graph Neural Networks",
#           and its implementation: https://github.com/graphdeeplearning/benchmarking-gnns.git
#       AND
#           Bresson et al. 2017, "Residual Gated Graph ConvNets"
#

import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

import os
import time
from contextlib import ExitStack
import numpy as np

import dgl
import torch
import torch.nn as Tnn
import torch.optim as Toptim

import config as Config
from label_estimation.graphs.gated_gcn_net import GatedGCN
from label_estimation.graphs.graph_datagen_davis_bin import GraphDatagenDAVIS_Binary
import util.util as Util

class GNNLabelEstimation():
    '''
    Member fields:
        videodata: VideoData instance; video data for the current video
        n_labels: int
        seedprop_alg: None or SeedPropagation subclass instance

        label_model: LabelModel subclass instance

        pred_generator: GraphDatagen instance, the generator used for generating the prediction
        
        net: LabelPropGatedGCN instance
        prev_pred_gs: list(n_ovr_preds) of DGL graph instances; the previous series of graphs generated by the prediction datagen iterator;
                                            includes all rounds of OvR, if OvR prediction was used
                                            only used by the debug gui to read out network inputs
        prev_binpred_ys: ndarray(n_ovr_preds, n_segs) of fl32; 
                                            the previous series of binary predicitons generated by the prediction datagen iterator;
                                            includes all rounds of OvR, if OvR prediction was used
                                            only used by the debug gui to read out network inputs
    '''

    def __init__(self, label_model, seedprop_alg=None):
        self.seedprop_alg = seedprop_alg
        self.label_model = label_model

        self.n_labels = None
        self.videodata = None
        self.net = None

        self.pred_generator = None
        self.prev_pred_gs = None
        self.prev_binpred_ys = None

    def set_prediction_video(self, vidname, videodata):
        '''
        Set video used for prediction. Needs to be called when we would like to make predictions on another video.
        Does not influence pretraining.
        '''
        self.videodata = videodata
        self.n_labels = self.videodata.get_data('n_labels')
        self.pred_generator = GraphDatagenDAVIS_Binary(vidname, self.videodata, "predict", self.label_model, self.seedprop_alg)

    def load_pretrained_gnn(self, checkpoint_path):
        '''
        Load a pretrained GNN model from a checkpoint file.
        '''
        self._init_net()
        self.net.load_state_dict(torch.load(checkpoint_path))

    def pretrain_gnn(self, tr_iter, val_iter):
        '''
        Pretrain a GNN model.
        Paramters:
            tr_iter: object implementing __iter__ (e.g. GraphTrainingDatasetDAVIS instance)
            val_iter: object implementing __iter__ (e.g. GraphTrainingDatasetDAVIS instance)
        '''
        self._init_net()
        self._pretrain_gnn_model(tr_iter, val_iter)

    def reset_prediction_generator(self):
        self.pred_generator.reset_prediction_iterator()

    def set_prediction_davis_state(self, new_annot_fr_idx, new_scribbles, state_prev_preds, state_seed_hist, state_seed_prop_hist):
        '''
        Parameters:
            <same as GraphDatagenDAVIS_Binary.set_session_state()>
        '''
        self.pred_generator.set_session_state(new_annot_fr_idx, new_scribbles, \
                                    state_prev_preds, state_seed_hist, state_seed_prop_hist)

    def get_prediction_davis_state(self):
        '''
        WARNING! The returned predicted image (return idx#0) is not updated !
        Returns:
            <same as GraphDatagenDAVIS_Binary.get_session_state()>
        '''
        return self.pred_generator.get_session_state()

    def predict_all(self, return_probs=False, verbose=True):
        '''
        Parameters:
            return_probs: bool
        Returns:
            ys_pred: ndarray(n_segs, n_cat) of fl32 (IF return_probs == True)
                     ndarray(n_segs,) of i32        (IF return_probs == False)
        '''
        EPS = 1e-9
        ys_pred_probs = self._predict_with_net(self.pred_generator)
        assert ys_pred_probs.shape[2:] == (1,)    # (n_samples, n_segs, 1:[binary_prob])
        self.prev_binpred_ys = ys_pred_probs[:,:,0]
        ys_pred_probs = ys_pred_probs[:,:,0].T      # (n_segs, n_samples)
        if self.n_labels == 2:
            if Config.PREDICTION_DOUBLE_ONE_VS_REST is True:
                assert ys_pred_probs.shape[-1] == 2
                # do nothing: ys_pred_probs is OK
            else:
                assert ys_pred_probs.shape[-1] == 1
                ys_pred_probs = np.concatenate([ys_pred_probs, 1.-ys_pred_probs], axis=1)
        else:
            if Config.PREDICTION_DOUBLE_ONE_VS_REST is True:
                assert ys_pred_probs.shape[-1] == self.n_labels*2
                ys_pred_probs[:,:self.n_labels] + (1.-ys_pred_probs[:,self.n_labels:])
            else:
                assert ys_pred_probs.shape[-1] == self.n_labels
                # do nothing: ys_pred_probs is OK

        ys_pred_probs_norm = ys_pred_probs / (np.sum(ys_pred_probs, axis=1, keepdims=True) + EPS)
        return ys_pred_probs_norm if return_probs is True else np.argmax(ys_pred_probs_norm, axis=1)

    # PRIVATE

    def _init_net(self):
        device = GNNLabelEstimation._gpu_setup(use_gpu=True, gpu_id=0)
        net_params = {}
        net_params['device'] = device
        net_params['in_dim_node'] = 19 if Config.GNN_ENABLE_NODE_FEATURE_SESSION_STEP_IDX is True else 18
        net_params['edge_feat'] = True
        net_params['in_dim_edge'] = 13
        net_params['hidden_dim'] = Config.GNN_HIDDEN_DIM
        net_params['out_dim'] = net_params['hidden_dim']
        net_params['L'] = Config.GNN_N_LAYERS    # n_layers
        net_params['dropout'] = Config.GNN_DROPOUT
        net_params['in_feat_dropout'] = Config.GNN_INFEAT_DROPOUT
        net_params['readout'] = Config.GNN_READOUT
        net_params['graph_norm'] = Config.GNN_GRAPH_NORM
        net_params['batch_norm'] = Config.GNN_BATCH_NORM
        net_params['residual'] = Config.GNN_RESIDUAL
        net_params['loss_name'] = Config.GNN_BINARY_LOSS

        net = GatedGCN(net_params)
        self.net = net.to(device)

    def _pretrain_gnn_model(self, tr_iter, val_iter):
        '''
        Pretrain with graphs and corresponding node label arrays.
        Paramters:
            tr_iter: object implementing __iter__ (e.g. GraphTrainingDatasetDAVIS instance)
            val_iter: object implementing __iter__ (e.g. GraphTrainingDatasetDAVIS instance)
        '''
        assert self.net is not None
        train_losses, val_losses = [], []
        t0 = time.time()
        per_epoch_time = []
        print("PRETRAINING GNN MODEL...")

        try:
            optimizer = Toptim.Adam(self.net.parameters(), lr=Config.GNN_INIT_LR, weight_decay=Config.GNN_WEIGHT_DECAY)
            scheduler = Toptim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=Config.GNN_LR_REDUCE_FACTOR,
                                                             patience=Config.GNN_LR_SCHEDULE_PATIENCE, verbose=True)
            for epoch_idx in range(Config.GNN_N_EPOCHS):
                print("    Epoch", epoch_idx) 
                time_start = time.time()
                epoch_train_loss, optimizer = self._run_net_one_epoch(tr_iter,\
                                    batch_size=1, ep_size=Config.GNN_TR_EPOCH_SIZE, optimizer=optimizer, is_training=True)
                epoch_val_loss, _ = self._run_net_one_epoch(val_iter, \
                                    batch_size=1, ep_size=Config.GNN_VAL_EPOCH_SIZE, optimizer=None, is_training=False)
                epoch_time = time.time()-time_start
                train_losses.append(epoch_train_loss)
                val_losses.append(epoch_val_loss)
                print("        t:", epoch_time, ", lr:", optimizer.param_groups[0]['lr'], ", tr_loss:", epoch_train_loss, \
                                ", val_loss:", epoch_val_loss)

                # Saving checkpoint
                if (epoch_idx % Config.GNN_N_EPOCHS_CHECKPOINT_FREQ == 0) and (epoch_idx > 0):
                    os.makedirs(Config.GNN_CHECKPOINT_DIR, exist_ok=True)
                    ckpt_path = os.path.join(Config.GNN_CHECKPOINT_DIR, "epoch_" + str(epoch_idx) + ".pkl")
                    torch.save(self.net.state_dict(), ckpt_path)
                    print("Checkpoint saved to:", ckpt_path)

                    # save loss plot
                    plot_path = os.path.join(Config.GNN_CHECKPOINT_DIR, "losses.png")
                    plt.figure(figsize=(12,6))
                    plt.plot(train_losses, label='train_loss')
                    plt.plot(val_losses, label='val_loss')
                    train_losses_m20 = Util.rolling_mean(train_losses, window_len=20)
                    val_losses_m20 = Util.rolling_mean(val_losses, window_len=20)
                    plt.plot(train_losses_m20, label='train_loss mean20')
                    plt.plot(val_losses_m20, label='val_loss mean20')
                    plt.legend()
                    plt.savefig(plot_path)
                    plt.clf()

                scheduler.step(epoch_val_loss)
                if optimizer.param_groups[0]['lr'] <= Config.GNN_MIN_LR:
                    print("\n!! LR EQUAL TO MIN LR SET.")
                    break
    
        except KeyboardInterrupt:
            print('-' * 89)
            print('Exiting from training early because of KeyboardInterrupt')
            
        print("TOTAL TIME TAKEN: {:.4f}hrs".format((time.time()-t0)/3600))
        #

    def _run_net_one_epoch(self, train_dataiter, batch_size, ep_size, optimizer, is_training):
        '''
        Parameters:
            train_dataiter: object implementing __iter__ (e.g. GraphTrainingDatasetDAVIS instance)
            batch_size, ep_size: int
            optimizer: None OR torch Optimizer instance; must not be non if training
            is_training: bool; can be used for validation loss/acc computation when 'is_training' is False
        Returns:
            epoch_loss: float
            optimizer: torch Optimizer instance
        '''
        if is_training:
            assert optimizer is not None
            self.net.train()
        else:
            self.net.eval()
        epoch_loss = 0.
        n_batches = 0
        if is_training:
            print("--- TRAINING")
        else:
            print("--- VALIDATION")

        # if not training enter "with torch.no_grad()" block
        train_it = train_dataiter.__iter__()
        with ExitStack() as context_stack:
            if not is_training:
                context_stack.enter_context(torch.no_grad())

            for sample_offset in range(0, ep_size, batch_size):
                time_start1 = time.time()
                batch_gs, batch_ys, batch_snorm_n, batch_snorm_e = next(train_it)

                # to gpu, train step
                batch_n = batch_gs.ndata['fs'].to(self.net.device)  # num x feat
                batch_e = batch_gs.edata['fs'].to(self.net.device)
                batch_ys = batch_ys.to(self.net.device)
                batch_snorm_e = batch_snorm_e.to(self.net.device)
                batch_snorm_n = batch_snorm_n.to(self.net.device)         # num x 1

                time_start2 = time.time()
                print("T delta batchgen: ", time_start2-time_start1)

                if is_training:
                    optimizer.zero_grad()
                batch_ys_preds = self.net.forward(batch_gs, batch_n, batch_e, batch_snorm_n, batch_snorm_e)
                loss = self.net.loss(batch_ys_preds, batch_ys)
                if is_training:
                    loss.backward()
                    optimizer.step()

                curr_train_vidgen = train_it.get_curr_vidgen()
                davisbin_bg_labs, davisbin_fg_labs = curr_train_vidgen.get_current_binary_label_split()
                n_labels = len(davisbin_bg_labs) + len(davisbin_fg_labs)
                assert n_labels == curr_train_vidgen.n_labels

                # 2 cases for prediction:
                #   when n_labels == 2 in the original multiclass setting, predictions from the net.forward are used
                #   when n_labels > 2 in the original multiclass setting, complete multiclass predictions cannot be given
                #       from the binary predicitons only, therefore a full OvR round is executed
                if n_labels == 2:
                    print("DAVIS bin predict: Using train-predict output...")
                    batch_ys_preds_single = batch_ys_preds.detach().cpu().numpy()  # (n_nodes, 1) of float
                    assert batch_ys_preds_single.shape[1:] == (1,)
                    batch_ys_preds_single = batch_ys_preds_single.reshape(-1)      # (n_nodes,) of float
                    batch_ys_preds_multi = np.empty((batch_ys_preds_single.shape[0], 2), dtype=np.float32)
                    if (davisbin_bg_labs[0] == 0) and (davisbin_fg_labs[0] == 1):
                        batch_ys_preds_multi[:,0] = 1. - batch_ys_preds_single
                        batch_ys_preds_multi[:,1] = batch_ys_preds_single
                    else:
                        assert (davisbin_bg_labs[0] == 1) and (davisbin_fg_labs[0] == 0)
                        batch_ys_preds_multi[:,0] = batch_ys_preds_single
                        batch_ys_preds_multi[:,1] = 1. - batch_ys_preds_single
                else:
                    print("DAVIS bin predict: Starting OvR...")
                    self.set_prediction_video(curr_train_vidgen.vidname, curr_train_vidgen.videodata)
                    self.reset_prediction_generator()
                    state_new_annot_fr_idx, _, _state2, _state3, _state4 = curr_train_vidgen._get_full_session_state()
                    # avoid adding any scribbles as only inference happens here, the state is not updated
                    self.set_prediction_davis_state(state_new_annot_fr_idx, None, _state2, _state3, _state4)
                    batch_ys_preds_multi = self.predict_all(return_probs=True)

                train_it.submit_predictions(batch_ys_preds_multi)

                print(" --> sample loss: ", loss.detach().cpu().numpy())

                time_start3 = time.time()
                print("T delta training per batch: ", time_start3-time_start2)

                epoch_loss += loss.detach().item()
                n_batches += 1

            epoch_loss /= n_batches

        return epoch_loss, optimizer

    def _predict_with_net(self, test_gen):
        '''
        Draw all sample graph from test_gen until expiry and predict with self.net. Batch size is fixed to 1.
        Binary prediction probabilities are kept, no conversion to multiclass.
        Parameters:
            test_gen: GraphDatagen instance in 'predict' mode;
        Returns:
            all_ys_preds: ndarray(n_samples, n_nodes, n_output_features) of float
        '''
        all_ys_preds = []
        self.prev_pred_gs = []
        self.net.eval()
        with torch.no_grad():
            for g in test_gen:
                assert isinstance(g, dgl.DGLGraph)
                self.prev_pred_gs.append(g)   # TODO fix, only used by the debug GUI

                n_nodes, n_edges = g.number_of_nodes(), g.number_of_edges()
                batch_snorm_n = torch.cat([torch.FloatTensor(n_nodes,1).fill_(1./float(n_nodes))], dim=0).sqrt()
                batch_snorm_e = torch.cat([torch.FloatTensor(n_edges,1).fill_(1./float(n_edges))], dim=0).sqrt()
                batch_gs = dgl.batch([g])

                batch_n = batch_gs.ndata['fs'].to(self.net.device)  # num x feat
                batch_e = batch_gs.edata['fs'].to(self.net.device)
                batch_snorm_e = batch_snorm_e.to(self.net.device)
                batch_snorm_n = batch_snorm_n.to(self.net.device)         # num x 1

                batch_ys_pred = self.net.forward(batch_gs, batch_n, batch_e, batch_snorm_n, batch_snorm_e)
                all_ys_preds.append(batch_ys_pred)

        all_ys_preds = torch.cat(all_ys_preds, dim=0).cpu().numpy()
        # isolate samples
        if all_ys_preds.ndim == 1:
            all_ys_preds = all_ys_preds.reshape(-1, n_nodes, 1)
        else:
            all_ys_preds = all_ys_preds.reshape(-1, n_nodes, all_ys_preds.shape[-1])
        return all_ys_preds


    # STATIC HELPERS

    @staticmethod
    def _gpu_setup(use_gpu, gpu_id):
        os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
        os.environ["CUDA_VISIBLE_DEVICES"] = str(gpu_id)  

        if torch.cuda.is_available() and use_gpu:
            print('cuda available with GPU:',torch.cuda.get_device_name(0))
            device = torch.device("cuda")
        else:
            print('cuda not available')
            device = torch.device("cpu")
        return device

    @staticmethod
    def balanced_accuracy_multiclass_torch(pred_ys, true_ys):
        # pred_ys: (n_samples, n_cats), true_ys: (n_samples,)
        pred_ys = pred_ys.detach()
        n_cats = pred_ys.shape[1]

        pred_ys = torch.argmax(pred_ys, dim=1).long()
        true_ys = true_ys.detach().long()
        assert pred_ys.shape == true_ys.shape

        # DEBUG temp
        true_ys = true_ys.cpu().numpy()
        pred_ys = pred_ys.cpu().numpy()
        acc_cats = []
        for cat_idx in range(n_cats):
            true_mask = true_ys == cat_idx
            pred_mask = pred_ys == cat_idx
            c_true = np.count_nonzero(true_mask)
            c_pred = np.count_nonzero(pred_mask)
            c_match = np.count_nonzero(pred_mask & true_mask)
            if c_true > 0:
                acc_cats.append(float(c_match)/float(c_true))
            print(" --> acc detailed", cat_idx, ":", c_match, "of", c_true, " (c_pred:", c_pred, ")")
        bal_acc = np.mean(acc_cats)
        # DEBUG END
        return bal_acc

